{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn: automated learning method selection and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to use Optunity in combination with sklearn to classify the digit recognition data set available in sklearn. The cool part is that we will use Optunity to choose the best approach from a set of available learning algorithms and optimize hyperparameters in one go. We will use the following learning algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* k-nearest neighbour\n",
    "* SVM\n",
    "* Naive Bayes\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will focus on a binary classification task, namely digit 3 versus digit 9. We start with the necessary imports and create the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import optunity\n",
    "import optunity.metrics\n",
    "import numpy as np\n",
    "\n",
    "# k nearest neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "n = digits.data.shape[0]\n",
    "\n",
    "positive_digit = 3\n",
    "negative_digit = 9\n",
    "\n",
    "positive_idx = [i for i in range(n) if digits.target[i] == positive_digit]\n",
    "negative_idx = [i for i in range(n) if digits.target[i] == negative_digit]\n",
    "\n",
    "# add some noise to the data to make it a little challenging\n",
    "original_data = digits.data[positive_idx + negative_idx, ...]\n",
    "data = original_data + 5 * np.random.randn(original_data.shape[0], original_data.shape[1])\n",
    "labels = [True] * len(positive_idx) + [False] * len(negative_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SVM model we will let Optunity optimize the kernel family, choosing from linear, polynomial and RBF. We start by creating a convenience functions for SVM training that handles this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svm(data, labels, kernel, C, gamma, degree, coef0):\n",
    "    \"\"\"A generic SVM training function, with arguments based on the chosen kernel.\"\"\"\n",
    "    if kernel == 'linear':\n",
    "        model = SVC(kernel=kernel, C=C)\n",
    "    elif kernel == 'poly':\n",
    "        model = SVC(kernel=kernel, C=C, degree=degree, coef0=coef0)\n",
    "    elif kernel == 'rbf':\n",
    "        model = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    else:\n",
    "        raise ArgumentError(\"Unknown kernel function: %s\" % kernel)\n",
    "    model.fit(data, labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = {'algorithm': {'k-nn': {'n_neighbors': [1, 5]},\n",
    "                        'SVM': {'kernel': {'linear': {'C': [0, 2]},\n",
    "                                           'rbf': {'gamma': [0, 1], 'C': [0, 10]},\n",
    "                                           'poly': {'degree': [2, 5], 'C': [0, 50], 'coef0': [0, 1]}\n",
    "                                           }\n",
    "                                },\n",
    "                        'naive-bayes': None,\n",
    "                        'random-forest': {'n_estimators': [10, 30],\n",
    "                                          'max_features': [5, 20]}\n",
    "                        }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@optunity.cross_validated(x=data, y=labels, num_folds=5)\n",
    "def performance(x_train, y_train, x_test, y_test,\n",
    "                algorithm, n_neighbors=None, n_estimators=None, max_features=None,\n",
    "                kernel=None, C=None, gamma=None, degree=None, coef0=None):\n",
    "    # fit the model\n",
    "    if algorithm == 'k-nn':\n",
    "        model = KNeighborsClassifier(n_neighbors=int(n_neighbors))\n",
    "        model.fit(x_train, y_train)\n",
    "    elif algorithm == 'SVM':\n",
    "        model = train_svm(x_train, y_train, kernel, C, gamma, degree, coef0)\n",
    "    elif algorithm == 'naive-bayes':\n",
    "        model = GaussianNB()\n",
    "        model.fit(x_train, y_train)\n",
    "    elif algorithm == 'random-forest':\n",
    "        model = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "                                       max_features=int(max_features))\n",
    "        model.fit(x_train, y_train)\n",
    "    else:\n",
    "        raise ArgumentError('Unknown algorithm: %s' % algorithm)\n",
    "\n",
    "    # predict the test set\n",
    "    if algorithm == 'SVM':\n",
    "        predictions = model.decision_function(x_test)\n",
    "    else:\n",
    "        predictions = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    return optunity.metrics.roc_auc(y_test, predictions, positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448066497878898"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance(algorithm='k-nn', n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'C': 26.328776041666668, 'algorithm': 'SVM', 'degree': 3.1683203125, 'n_neighbors': None, 'n_estimators': None, 'max_features': None, 'coef0': 0.6699829257450541, 'gamma': None}\n",
      "0.981895001496\n"
     ]
    }
   ],
   "source": [
    "optimal_configuration, info, _ = optunity.maximize_structured(performance,\n",
    "                                                              search_space=search,\n",
    "                                                              num_evals=300)\n",
    "print(optimal_configuration)\n",
    "print(info.optimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
